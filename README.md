# 강의 소개
본 강의는 데이터 엔지니어링 기초 부분을 단기간에 훑어보는 코스입니다.  
강의 기간동안 수강생들은 데이터 엔지니어링의 개념이해와 데이터 엔지니어링의 기반 기술들을 어떻게 사용하고 어떻게 프로그래밍 하는지, 그리고 데이터 엔지니어들이 실무에서 고민하는 사항들이 무엇인지 등을 학습할 수 있습니다.  
따라서 이 강의는 *데이터 엔지니어링 기초코스*에 초점을 맞추고 있습니다.  

# 수강 대상자
최소 아래의 언어로 프로그래밍을 할 수 있는 사람이어야 합니다.  
- Python
- Java
- Scala
  
다음은 몰라도 수업을 하는데 큰 지장이 없지만(모를 경우 좀 더 많은 학습량을 요구합니다), 미리 알고 있다면 수업을 따라가는데 매우 큰 도움이 되는 것들입니다.
- Shell(Linux commands)
- SQL
- Docker

# 준비물
- Labtop/Desktop(최소 RAM 8G 이상, 8G 미만은 제공되는 Docker image 실행이 힘듭니다)

# 수업에서 사용하게 될 기술
- PostgreSQL
- Apache Hadoop
- Apache Hive
- Apache Spark
- Apache Airflow
- Grafana
- Docker
- Shell

# 수업 목표
데이터 처리에 사용되는 기술을 전반적으로 훑어보고, 데이터 엔지니어가 되기 위한 기초적인 지식을 쌓음.

## 기대해도 되는 수업 후 성과
- 데이터 엔지니어링과 데이터 엔지니어가 하는 일, 전망 등에 대한 이해
- Database 기본(SQL language 학습)
- Data lake 개념 이해
- Big data 기반 기술에 대한 기초적 이해(Apache Hadoop 개념, HDFS command)
- Big data 처리 및 기술에 대한 기초적 이해(Apache Hive, Spark 개념, 사용법, 프로그래밍)
- Workflow 구성에 대한 기초적 이해(Apache Airflow)
- 데이터 시각화 사용법에 대한 기초적 이해

## 기대하기 어려운 수업 후 성과
- Hadoop 클러스터 운영 기술
- Cloud 기반의 데이터 처리
- Spark query 최적화
- DB 최적화
- Frontend/Backend 등 다른 분야의 Software engineering 스킬

# 강의 계획서

## Week1. 강의 소개, 데이터 엔지니어링의 개념, SQL 기본
- 강의 소개
- 데이터 엔지니어링과 데이터 엔지니어에 대해서
- SQL 기본 및 PostgreSQL(실습)
- Python/Java에서 DB Query하기(실습)
- 과제소개

## Week2. 병렬처리, Hadoop Map reduce와 실습
- 지난 주 과제리뷰
- 병렬처리
- Apache Hadoop 개념
- Hadoop Map reduce 개념
- Hadoop command(실습)
- Map reduce 프로그램 작성하기(실습)
- 과제소개

## Week3. Apache Hive
- Apache Hive 개념
- Hive Query(실습)
- 지난 주 과제리뷰
- 기본적인 Table 구조 및 Query 최적화(실습)
- Hive의 한계점과 Hive를 대체하는 기술들
- 과제소개

## Week4. Apache Spark
- Apache Spark 개념
- Spark 병렬처리
- Spark programming(실습)
- Spark SQL
- Spark SQL script(실습)
- 과제소개

## Week5. Workflow 구성
- 과제리뷰
- Job scheduling, Workflow 구성
- Airflow 개념
- Airflow로 Workflow 구성 및 스케줄 설정(실습)
- 과제소개

## Week6. 데이터 시각화
- 과제리뷰
- Grafana 둘러보기
- 데이터 시각화(실습)
- 과제소개

## Week7. Term project
- 데이터 수집, 처리 및 시각화 파이프라인 개발(전일 실습)

## Week8. 코스 리뷰
- Term project 리뷰
- Big tech 회사들의 데이터 파이프라인 아키텍처
- 데이터 엔지니어 커리어 조언

